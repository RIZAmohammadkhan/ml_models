{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b11bf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# reading data\n",
    "\n",
    "data = pd.read_csv(\"..\\datasets\\space.csv\")\n",
    "testData = pd.read_csv(\"..\\datasets\\spacetest.csv\")\n",
    "ligible_y = data['Transported']\n",
    "result_id = testData['PassengerId']\n",
    "del  data['Transported']\n",
    "del data['Name']\n",
    "del testData['Name']\n",
    "del data['PassengerId']\n",
    "del testData['PassengerId']\n",
    "del data['Cabin']\n",
    "del testData['Cabin']\n",
    "\n",
    "\n",
    "# getting strings\n",
    "stringColumns = []\n",
    "numericColumns = []\n",
    "for i in data.columns:\n",
    "    if data[i].dtype == 'object':\n",
    "        stringColumns.append(i)\n",
    "    else:\n",
    "        numericColumns.append(i)\n",
    "\n",
    "\n",
    "labelColumns = []\n",
    "oneHotColumns = []\n",
    "for i in stringColumns:\n",
    "    if len(data[i].unique()) == 3:\n",
    "        labelColumns.append(i)\n",
    "    else:\n",
    "        oneHotColumns.append(i)\n",
    "oneHotColumns\n",
    "\n",
    "# Handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "SI = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "data[stringColumns] = SI.fit_transform(data[stringColumns])\n",
    "testData[stringColumns] = SI.transform(testData[stringColumns])\n",
    "\n",
    "SI = SimpleImputer(strategy='median')\n",
    "data[numericColumns] = SI.fit_transform(data[numericColumns])\n",
    "testData[numericColumns] = SI.transform(testData[numericColumns])\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in labelColumns:\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "    testData[i] = le.transform(testData[i])\n",
    "y = le.fit_transform(ligible_y)\n",
    "\n",
    "\n",
    "# One Hot Encoding\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oe = OneHotEncoder()\n",
    "for i in oneHotColumns:\n",
    "    oe.fit(data[[i]])\n",
    "    temp_data = pd.DataFrame(oe.transform(data[[i]]).toarray(), columns=oe.get_feature_names_out([i]))\n",
    "    data = pd.concat([data,temp_data], axis=1)\n",
    "    del data[i]\n",
    "    temp_testData = pd.DataFrame(oe.transform(testData[[i]]).toarray(), columns=oe.get_feature_names_out([i]))\n",
    "    testData = pd.concat([testData,temp_testData], axis=1)\n",
    "    del testData[i]\n",
    "\n",
    "\n",
    "# scaling both datas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "scaled_data = scale.fit_transform(data)\n",
    "scaled_test_data = scale.transform(testData)\n",
    "\n",
    "# Convert numpy arrays back to pandas dataframes\n",
    "data_final = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "testData_final = pd.DataFrame(scaled_test_data, columns=testData.columns)\n",
    "\n",
    "# trainig the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aed6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object on the training data\n",
    "grid.fit(data_final, y)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "best_model = grid.best_estimator_\n",
    "predictions = best_model.predict(testData_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29206ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65140f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = le.inverse_transform(predcitions.reshape(-1,1))\n",
    "\n",
    "test_results = pd.DataFrame({'PassengerId': result_id, 'Transported': values})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
